# WGAN-GP 技术文档

## 1. 算法原理

### 1.1 传统GAN的问题

传统的生成对抗网络（GAN）使用JS散度作为生成分布和真实分布之间的距离度量，存在以下问题：

1. **训练不稳定**：生成器和判别器难以平衡
2. **梯度消失**：当判别器过强时，生成器梯度接近零
3. **模式崩溃**：生成器只生成少数几种模式的样本

### 1.2 WGAN的改进

WGAN（Wasserstein GAN）使用Wasserstein距离（Earth-Mover距离）替代JS散度：

```
W(P_r, P_g) = inf_{γ∈Π(P_r, P_g)} E_(x,y)~γ[||x - y||]
```

通过Kantorovich-Rubinstein对偶性，可以表示为：

```
W(P_r, P_g) = sup_{||f||_L≤1} E_x~P_r[f(x)] - E_x~P_g[f(x)]
```

其中 `||f||_L≤1` 表示f是1-Lipschitz连续函数。

**优势**：
- 提供有意义的损失度量
- 训练更稳定
- 不易发生模式崩溃

### 1.3 WGAN-GP的梯度惩罚

原始WGAN使用权重裁剪（weight clipping）来满足Lipschitz约束，但这会导致：
- 容量不足
- 梯度消失或爆炸

**WGAN-GP的解决方案**：使用梯度惩罚（Gradient Penalty）替代权重裁剪

目标函数：

```
L = E_x̃~P_g[D(x̃)] - E_x~P_r[D(x)] + λ·E_x̂~P_x̂[(||∇_x̂D(x̂)||_2 - 1)²]
```

其中：
- 第一项：假样本的判别器输出（希望最大化）
- 第二项：真样本的判别器输出（希望最小化）
- 第三项：梯度惩罚项
- `x̂ = εx + (1-ε)x̃`：真假样本的线性插值
- `λ`：惩罚系数，通常设为10

## 2. 网络架构

### 2.1 生成器架构

生成器采用DCGAN架构，使用转置卷积进行上采样：

```
输入: 潜在向量 z ∈ R^128
  ↓
全连接层 (128 → 512×4×4)
  ↓
BatchNorm + ReLU
  ↓
Reshape (512, 4, 4)
  ↓
ConvTranspose2d (512 → 256, kernel=4, stride=2) → 8×8
BatchNorm + ReLU
  ↓
ConvTranspose2d (256 → 128, kernel=4, stride=2) → 16×16
BatchNorm + ReLU
  ↓
ConvTranspose2d (128 → 64, kernel=4, stride=2) → 32×32
BatchNorm + ReLU
  ↓
ConvTranspose2d (64 → 3, kernel=4, stride=2) → 64×64
Tanh
  ↓
输出: 图像 (3, 64, 64)，范围 [-1, 1]
```

**关键设计**：
- 使用BatchNorm稳定训练
- 使用ReLU激活函数
- 最后一层使用Tanh将输出限制在[-1, 1]
- 不使用全连接层（除了第一层）

### 2.2 判别器架构

判别器使用卷积层进行下采样：

```
输入: 图像 (3, 64, 64)
  ↓
Conv2d (3 → 64, kernel=4, stride=2) → 32×32
LeakyReLU(0.2)
  ↓
Conv2d (64 → 128, kernel=4, stride=2) → 16×16
LayerNorm + LeakyReLU(0.2)
  ↓
Conv2d (128 → 256, kernel=4, stride=2) → 8×8
LayerNorm + LeakyReLU(0.2)
  ↓
Conv2d (256 → 512, kernel=4, stride=2) → 4×4
LayerNorm + LeakyReLU(0.2)
  ↓
AdaptiveAvgPool2d(1) + Flatten
  ↓
全连接层 (512 → 1)
  ↓
输出: 标量评分（实数）
```

**关键设计**：
- 使用LayerNorm而非BatchNorm（WGAN-GP推荐）
- 使用LeakyReLU(0.2)激活函数
- 不使用Sigmoid（输出实数评分）
- 使用步长为2的卷积进行下采样

## 3. 训练策略

### 3.1 训练流程

```python
for epoch in range(num_epochs):
    for real_images in dataloader:
        # 1. 训练判别器 n_critic 次
        for _ in range(n_critic):
            # 生成假图像
            z = sample_noise()
            fake_images = G(z)
            
            # 计算判别器损失
            d_real = D(real_images)
            d_fake = D(fake_images)
            
            # 计算梯度惩罚
            gp = compute_gradient_penalty(D, real_images, fake_images)
            
            # 总损失
            d_loss = d_fake.mean() - d_real.mean() + λ * gp
            
            # 更新判别器
            d_loss.backward()
            optimizer_D.step()
        
        # 2. 训练生成器 1 次
        z = sample_noise()
        fake_images = G(z)
        g_loss = -D(fake_images).mean()
        
        g_loss.backward()
        optimizer_G.step()
```

### 3.2 超参数设置

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| 学习率（G） | 0.0001 | Adam优化器学习率 |
| 学习率（D） | 0.0001 | Adam优化器学习率 |
| β1 | 0.0 | Adam的第一动量系数 |
| β2 | 0.9 | Adam的第二动量系数 |
| batch_size | 64 | 批次大小 |
| n_critic | 5 | 判别器训练频率 |
| λ (lambda_gp) | 10 | 梯度惩罚系数 |
| latent_dim | 128 | 潜在空间维度 |

### 3.3 训练技巧

1. **判别器多次训练**：每训练1次生成器，训练5次判别器
2. **学习率选择**：使用较小的学习率（0.0001）
3. **优化器参数**：β1=0.0 对WGAN-GP很重要
4. **归一化**：图像归一化到[-1, 1]
5. **权重初始化**：使用正态分布N(0, 0.02)初始化

## 4. 梯度惩罚实现

### 4.1 数学推导

对于插值样本 `x̂ = εx + (1-ε)x̃`，我们希望：

```
||∇_x̂D(x̂)||_2 ≈ 1
```

梯度惩罚项：

```
L_GP = E_x̂[(||∇_x̂D(x̂)||_2 - 1)²]
```

### 4.2 代码实现

```python
def compute_gradient_penalty(D, real_samples, fake_samples, device):
    # 随机权重
    alpha = torch.rand(batch_size, 1, 1, 1).to(device)
    
    # 插值
    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples)
    interpolates.requires_grad_(True)
    
    # 判别器输出
    d_interpolates = D(interpolates)
    
    # 计算梯度
    gradients = torch.autograd.grad(
        outputs=d_interpolates,
        inputs=interpolates,
        grad_outputs=torch.ones_like(d_interpolates),
        create_graph=True,
        retain_graph=True,
    )[0]
    
    # 梯度范数
    gradients = gradients.view(batch_size, -1)
    gradient_norm = gradients.norm(2, dim=1)
    
    # 惩罚项
    gradient_penalty = ((gradient_norm - 1) ** 2).mean()
    
    return gradient_penalty
```

## 5. 数据预处理

### 5.1 图像预处理流程

```python
transform = transforms.Compose([
    transforms.Resize((64, 64)),      # 调整大小
    transforms.ToTensor(),             # 转换为张量 [0, 1]
    transforms.Normalize(              # 归一化到 [-1, 1]
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])
```

### 5.2 数据增强（可选）

对于数据较少的情况，可以添加数据增强：

```python
transform = transforms.Compose([
    transforms.Resize((72, 72)),
    transforms.RandomCrop((64, 64)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])
```

## 6. 评估指标

### 6.1 Fréchet Inception Distance (FID)

FID测量真实图像和生成图像在Inception网络特征空间中的距离：

```
FID = ||μ_r - μ_g||² + Tr(Σ_r + Σ_g - 2(Σ_r·Σ_g)^(1/2))
```

- **越低越好**
- FID < 50：质量较好
- FID < 20：质量优秀

### 6.2 Inception Score (IS)

IS评估生成图像的质量和多样性：

```
IS = exp(E_x[KL(p(y|x) || p(y))])
```

- **越高越好**
- IS > 3：质量可接受
- IS > 5：质量良好

### 6.3 Wasserstein距离

训练过程中监控的Wasserstein距离：

```
W ≈ E[D(x_real)] - E[D(x_fake)]
```

- 收敛时应接近0
- 稳定的W距离表示训练稳定

## 7. 常见问题与解决方案

### 7.1 训练不稳定

**症状**：损失剧烈波动，生成图像质量不稳定

**解决方案**：
- 降低学习率（0.0001 → 0.00005）
- 增加n_critic（5 → 10）
- 检查梯度惩罚实现
- 使用Spectral Normalization

### 7.2 模式崩溃

**症状**：生成的图像缺乏多样性

**解决方案**：
- 增加λ_gp（10 → 20）
- 使用更大的批次大小
- 增加训练数据多样性
- 尝试minibatch discrimination

### 7.3 生成图像模糊

**症状**：生成的图像不够清晰

**解决方案**：
- 延长训练时间
- 使用更深的网络
- 增加特征图数量
- 添加自注意力机制

### 7.4 收敛缓慢

**症状**：训练很慢，质量提升不明显

**解决方案**：
- 使用预训练判别器
- 增加学习率（谨慎）
- 使用学习率衰减
- 增加批次大小

## 8. 性能优化

### 8.1 混合精度训练

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    fake_images = generator(z)
    d_loss = compute_discriminator_loss()

scaler.scale(d_loss).backward()
scaler.step(optimizer_D)
scaler.update()
```

### 8.2 多GPU训练

```python
if torch.cuda.device_count() > 1:
    generator = nn.DataParallel(generator)
    discriminator = nn.DataParallel(discriminator)
```

### 8.3 内存优化

- 使用梯度累积
- 减小批次大小
- 使用梯度检查点
- 及时清理中间变量

## 9. 部署与应用

### 9.1 模型导出

```python
# 导出为ONNX格式
dummy_input = torch.randn(1, 128)
torch.onnx.export(
    generator,
    dummy_input,
    "generator.onnx",
    opset_version=11
)
```

### 9.2 推理优化

```python
# TorchScript
traced_generator = torch.jit.trace(generator, dummy_input)
traced_generator.save("generator_traced.pt")

# 使用
generator = torch.jit.load("generator_traced.pt")
generator.eval()
```

## 10. 参考实现

### 10.1 关键代码片段

完整实现请参考项目源代码：
- `models/generator.py`: 生成器实现
- `models/discriminator.py`: 判别器实现
- `models/wgan_gp.py`: WGAN-GP模型封装
- `src/train.py`: 训练脚本
- `src/generate.py`: 生成脚本

### 10.2 配置文件

所有超参数在 `config/config.yaml` 中配置，便于实验和调优。

## 11. 扩展与改进

### 11.1 条件生成（CWGAN-GP）

添加标签信息进行条件生成：
- 在生成器和判别器中加入类别嵌入
- 可以控制生成特定类型的二次元图像

### 11.2 渐进式训练

参考Progressive GAN：
- 从低分辨率开始训练
- 逐步增加分辨率
- 生成更高质量的图像

### 11.3 自注意力机制

参考SAGAN：
- 在生成器和判别器中添加Self-Attention层
- 更好地捕捉全局依赖关系

---

**注意**：本文档持续更新中，如有问题请提Issue讨论。
